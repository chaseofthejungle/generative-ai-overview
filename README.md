# Generative AI Overview Guide

**TODO:** A brief introductory guide, outlining the basics of Generative AI ('Gen AI').

#### Table of Contents

1. [Defining 'Generative AI'](#defining)
2. [Key Mathematical Concepts](#keyconcepts)
3. [Generative AI Foundational Models](#models)
4. [Generative AI Development Stack](#stack)
5. [Training the Model](#training)
6. [Building Out AI Agents](#building)
7. [Generative AI Training Providers](#materials)
8. [Supplemental Resources](#supplemental)

<hr />

## 1. <a name="defining">Defining 'Generative AI'</a>

*Generative AI* can be conceptualized through a 4-layer paradigm, with each descending layer conceptually 'contained' within the previous layers and culminating with 'Generative AI'. From most general to most specific:

1) **Artificial Intelligence (AI):** Human-developed information systems appear to possess *Artificial Intelligence* when they process tasks: it is as if they are thinking for themselves.
2) **Machine Learning:** When algorithms empower artificially intelligent systems with the ability to 'learn' from data (consequently, systems appear to be more intelligent).
3) **Deep Learning:** When machine learning goes farther: algorithms can recognize patterns in data and make predictions via artificial neural networks.
4) **Generative AI:** Fresh content is developed (generated) by the AI system based on what has been learned.

<hr />

## 2. <a name="keyconcepts">Key Mathematical Concepts</a>

* **Calculus:** Allows AI models to 'learn'. Relies on *gradient descent*, or algorithmically informing the model how to modify/fine-tune parameters to reduce errors. The integration of calculus prevents AI models from making purely random guesses, instead measuring rates of change (*derivatives*).
  + Partial derivatives are stored as one vector (*gradient*). Values are fine-tuned as the AI 'learns'.
* **Linear Algebra:** Handles data structures (e.g, matrices, vectors) and represents weights/inputs for neural networks.
  + Each row of a set of data is represented as a matrix or a vector. For example, one point of data (e.g., employee's salary, SSN) can be represented as a vector.
    - When multiple employees in this example are grouped/stacked together, this forms a matrix.
* **Probability and Bayesian Statistics:** Assists AI models with handling uncertain (entropic) outcomes. Predictions are generated by calculating likelihood based on available data.
  + *Bayes' theorem* empowers AI models to modify conclusions in light of new data.

<hr />

## 3. <a name="models">Generative AI Foundational Models</a>

| *Model* | *Strengths* | *Potential Limitations* |
| :---: | :---: | :----: |
| **Claude** | Safe, Less Rigid (more human-like) Writing Style, Can Handle Lengthy Text Data | Context and Prompt Rates (Subscriptions or API Access may be necessary). |
| **DeepSeek** | Robust Logic, High Processing Efficiency of Coding and Technical Tasks, Low Cost | Multimodal Constraints. |
| **Gemini** | Complex Logic Capabilities, Capable of Handling Massive Contexts, Highly Multimodal | Context and Prompt Rates (Subscriptions or API Access may be necessary). |
| **GPT** | Generates Complex Content, Handles Complex Prompts, Broad Dialogue Capabilities | Context and Prompt Rates (Subscriptions or API Access may be necessary). |
| **Llama** | Open-Source, Capability of Handling Massive Contexts, Multi-Lingual Support | Focus on Functionality May Make It Less Suitable for Subjectively Nuanced Tasks. |

<hr />

## 4. <a name="stack">Generative AI Development Stack</a>

<hr />

## 5. <a name="training">Training the Model</a>

1) **Data Training**: Gen AIs learn to identify patterns from being fed massive quantities of relevant data (e.g., text, video, images, audio).
2) **Accuracy Training**: Gen AIs perform generation accuracy learning through the algorithmic detection of error ratios (loss functions) between their model's output and the idealized output.
3) **Analyzing Quality**: Mechanisms/metrics are selected for determining how satisfactory generated data are.
4) **Avoiding Mode Collapse and Overfitting**: Gen AIs need to avoid an overly narrow output range (mode collapsing), as well as simply recognizing the training data without being able to dive deeper into its indications (overfitting)
5) **Conditional Generation**: This type of Gen AI can generate outputs in response to inputs and constraints (conditions).
6) **Fine-Tuning**: Weights and parameters can be kept static or made dynamic (as necessary), with evaluation (in comparison to targets) occurring afterward.

<hr />

## 6. <a name="building">Building Out AI Agents</a>

<hr />

## 7. <a name="materials">Generative AI Training Providers</a>

* **[DeepLearning.AI](https://www.deeplearning.ai/):** An education technology company that provides international and collaborative training/educational opportunities for construting AI-oriented solutions.
* **[Google Labs](https://labs.google/):** A platform for testing/previewing Google's products and services (including AI-oriented ones, such as personalized AI collaborators, feedback mechanisms, and AI overviews) before they are officially released.
* **[Kaggle](https://www.kaggle.com/):** An online community/hub and competitive data science problem solving platform, acquired by Google in 2017. It provides machine learning and data scientists with the ability to discover and publish their models and data sets, as well as collaborate with other machine learning and data professionals.
* **[Nvidia Academy](https://academy.nvidia.com/en/):** Provides self-paced/asynchronous AI learning (knowledge and skills) courses (many of which are free).

<hr />

## 8. <a name="supplemental">Supplemental Resources</a>

* *[Four AI Model Types Overview](https://github.com/chaseofthejungle/four-ai-models-overview)*
* *[Agentic AI and AI Agents Overview](https://github.com/chaseofthejungle/agentic-ai-and-ai-agents-overview)*
* *[AI Architecture Model Overview Guide](https://github.com/chaseofthejungle/AI-Architecture-Model-Overview)*
